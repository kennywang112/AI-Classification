{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6860154d-5760-4c6e-a55a-f65e41c147cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import gradio as gr\n",
    "import os\n",
    "import openai\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661cb30f-e2e1-4874-84f6-7d20c4fedb54",
   "metadata": {},
   "source": [
    "## Ê∏¨Ë©¶gpt api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277e89ba-da6b-4e35-a588-07842518f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/texes.txt', 'r', encoding='utf-8') as fh:\n",
    "    tmp = fh.read()\n",
    "    itemlist = tmp.split(',')\n",
    "\n",
    "itemlist = str(itemlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925001f9-3e5e-4436-81c6-bbbbf6880567",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyfile = open(\"key.txt\", \"r\")\n",
    "key = keyfile.readline()\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ae79f28-3a0a-46be-b33d-6a21191b6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_idx = 0\n",
    "# result = ''\n",
    "# while start_idx < len(itemlist):\n",
    "#     end_idx = min(start_idx + 1600, len(itemlist))\n",
    "#     sub_list = itemlist[start_idx:end_idx]\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"ada\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
    "#             {\"role\": \"user\", \"content\": f\"Êèê‰æõ‰ª•‰∏äÊñáÂ≠ó‰πãÁπÅÈ´î‰∏≠ÊñáÊëòË¶ÅËàáËã±ÊñáÁøªË≠ØÔºö{sub_list}\"}\n",
    "#         ]\n",
    "#     )  \n",
    "#     for choice in response.choices:\n",
    "#         result += choice.message.content\n",
    "#     print(start_idx)\n",
    "#     start_idx = end_idx\n",
    "\n",
    "# with open('output.txt', 'w', encoding='utf-8') as output_file:\n",
    "#     output_file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bcf9d-dcd7-430f-ae33-86e2682a7b91",
   "metadata": {},
   "source": [
    "## ËôïÁêÜÂ∑≤Ë®ìÁ∑¥Ê®°ÁµÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e21775-11df-4b77-b78f-f92ad77691e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 21:50:41.836940: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(\"model_epoch_06.h5\", compile=False)\n",
    "model_config = loaded_model.get_config()\n",
    "#loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40fcfd1b-0bbf-41f6-bcb5-73951ca3485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(img):\n",
    "\n",
    "    # Resize the image to match the input shape of your model\n",
    "    img = img.resize((256, 256))  # Adjust the size as needed\n",
    "    # Convert the image to a NumPy array\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    # Preprocess the image to match the model's input requirements\n",
    "    img_np = keras_image.img_to_array(img_np)\n",
    "    \n",
    "    img_for_plot = img_np / 255.0  # Normalize the image if necessary\n",
    "    \n",
    "    img_np = np.expand_dims(img_np, axis=0)  # Add a batch dimension\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(img_np)\n",
    "    \n",
    "    return img_for_plot, predictions\n",
    "\n",
    "def image_mod(img):\n",
    "    \n",
    "    image, predictions = pred(img)\n",
    "\n",
    "    print(predictions)\n",
    "    \n",
    "    result = \"\"\n",
    "    \n",
    "    if predictions[0][0] == 0.0:\n",
    "\n",
    "        result = \"fake image\"\n",
    "    else :\n",
    "        \n",
    "        result = \"true image\"\n",
    "\n",
    "    return result\n",
    "\n",
    "def chatbtn(content):\n",
    "    \n",
    "    print(content)\n",
    "    \n",
    "    return content\n",
    "\n",
    "def display_image_from_video(video):\n",
    "\n",
    "    capture_image = cv.VideoCapture(video) \n",
    "    # Áç≤ÂèñË¶ñÈ†ª‰∏≠ÁöÑ‰∏ÄÂπÄÔºåËÆäÊï∏ÂàÜÂà•ÁÇ∫ÊòØÂê¶ÊàêÂäüËÆÄÂèñ‰∫Ü‰∏ÄÂπÄ‰ª•ÂèäÊçïÁç≤ÁöÑÂúñÂÉèÂπÄ\n",
    "    ret, frame = capture_image.read()\n",
    "# \n",
    "#     frame = frame[0].resize((256, 256))\n",
    "    \n",
    "#     img_np = np.array(frame)\n",
    "#     img_np = keras_image.img_to_array(img_np)\n",
    "    \n",
    "#     img_np = np.expand_dims(img_np, axis=0)\n",
    "    \n",
    "#     # Make predictions\n",
    "#     predictions = loaded_model.predict(img_np)\n",
    "    \n",
    "    return frame[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d534885-2796-4907-9e69-9ec81d275c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/gradio/blocks.py\", line 1185, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/gradio/utils.py\", line 661, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/w2/_g9w5yys0f171q4qqm469z1h0000gn/T/ipykernel_48067/1506131244.py\", line 52, in display_image_from_video\n",
      "    img_np = keras_image.img_to_array(img_np)\n",
      "  File \"/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/keras/utils/image_utils.py\", line 310, in img_to_array\n",
      "    raise ValueError(f'Unsupported image shape: {x.shape}')\n",
      "ValueError: Unsupported image shape: ()\n"
     ]
    }
   ],
   "source": [
    "title = \"\"\"<h1 align=\"center\">AIËáâÈÉ®Ëæ®Ë≠òüöÄ</h1>\"\"\"\n",
    "                \n",
    "with gr.Blocks(css = \"\"\".gradio-container {background-color: #3f7791}\"\"\") as demo:\n",
    "    gr.HTML(title)\n",
    "    gr.HTML('''<center><a href=\"https://github.com/kennywang112?tab=repositories\" alt=\"GitHub Repo\"></a></center>''')\n",
    "    with gr.Row():\n",
    "        \n",
    "        with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "            chatbot = gr.Chatbot(elem_id='chatbot')\n",
    "            inputs = gr.Textbox(placeholder= \"Hi there!\", label= \"Type an input and press Enter\")\n",
    "            state = gr.State([])\n",
    "            btn = gr.Button('ask') \n",
    "            \n",
    "        btn.click(chatbtn, [inputs], [])\n",
    "\n",
    "        with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "            gr.Interface(\n",
    "                image_mod,\n",
    "                gr.Image(type=\"pil\"),\n",
    "                gr.components.Text(),\n",
    "                examples=[\n",
    "                    os.path.join(\"images/real_face0.jpeg\"),\n",
    "                    os.path.join(\"images/real_face1.jpeg\"),\n",
    "                    os.path.join(\"images/fake_face1.jpeg\"),\n",
    "                    os.path.join(\"images/fake_face0.jpeg\"),\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "        with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "            inputs = gr.components.Video()\n",
    "            outputs = gr.components.Text()\n",
    "            # outputs = gr.components.Image()\n",
    "            update = gr.Button('Áç≤ÂèñÂΩ±ÁâáÂúñÂÉè')\n",
    "\n",
    "            update.click(display_image_from_video, inputs = [inputs], outputs = [outputs])\n",
    "    \n",
    "demo.queue().launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
