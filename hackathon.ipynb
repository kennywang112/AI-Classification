{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6860154d-5760-4c6e-a55a-f65e41c147cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import gradio as gr\n",
    "import os\n",
    "import openai\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661cb30f-e2e1-4874-84f6-7d20c4fedb54",
   "metadata": {},
   "source": [
    "## æ¸¬è©¦gpt api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277e89ba-da6b-4e35-a588-07842518f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/texes.txt', 'r', encoding='utf-8') as fh:\n",
    "    tmp = fh.read()\n",
    "    itemlist = tmp.split(',')\n",
    "\n",
    "itemlist = str(itemlist)\n",
    "itemlist\n",
    "\n",
    "keyfile = open(\"key.txt\", \"r\")\n",
    "key = keyfile.readline()\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae79f28-3a0a-46be-b33d-6a21191b6610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é€™å¼µåœ–ç‰‡æ˜¯ä¸€å€‹å‹•æ¼«é¢¨æ ¼çš„è§’è‰²é ­åƒã€‚è§’è‰²æ˜¯ä¸€åå¹´è¼•ç”·æ€§ï¼Œå…·æœ‰æ£•è‰²çš„è“¬é¬†çŸ­é«®ï¼Œé«®å‹ç•¥é¡¯å‡Œäº‚ã€‚ä»–æœ‰ä¸€å°æ·±è‰²çš„çœ¼ç›å’Œç´°é•·çš„çœ‰æ¯›ã€‚ä»–çš„è¡¨æƒ…é¡¯å¾—å¹³éœä¸”ç•¥å¸¶åš´è‚…ï¼Œå˜´å·´é–‰åˆï¼Œæ²’æœ‰å¾®ç¬‘ã€‚è§’è‰²çš„çš®è†šæ˜¯å…‰æ»‘ä¸”å‘ˆè‡ªç„¶çš„è†šè‰²ã€‚åœ–åƒåªå±•ç¤ºäº†è§’è‰²çš„é ­éƒ¨å’Œé ¸éƒ¨ä¸€éƒ¨åˆ†ã€‚\n",
      "\n",
      "æ­¤åœ–åƒçš„ç°¡å–®é¢¨æ ¼å’ŒæŸ”å’Œçš„é¡è‰²è¨­è¨ˆä½¿å…¶é©åˆå‹•æ¼«æˆ–ç¶²çµ¡æ¼«ç•«ã€‚å› ç‚ºåœ–ç‰‡æ²’æœ‰æä¾›èƒŒæ™¯æˆ–å…¶ä»–èƒŒæ™¯å…ƒç´ ï¼Œæ‰€ä»¥ç„¦é»å®Œå…¨é›†ä¸­åœ¨é€™å€‹è§’è‰²ä¸Šã€‚\n"
     ]
    }
   ],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"/Users/wangqiqian/desktop/é»‘å®¢æ¾/AI_classification/images/fake_face0.jpeg\"\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "start_idx = 0\n",
    "result = ''\n",
    "while start_idx < len(itemlist):\n",
    "    end_idx = min(start_idx + 1600, len(itemlist))\n",
    "    sub_list = itemlist[start_idx:end_idx]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": sub_list},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        max_tokens = 300\n",
    "    )  \n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    start_idx = end_idx\n",
    "\n",
    "with open('output.txt', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(result)\n",
    "\n",
    "output = open(\"output.txt\", \"r\", encoding=\"utf-8\")\n",
    "print(output.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bcf9d-dcd7-430f-ae33-86e2682a7b91",
   "metadata": {},
   "source": [
    "## è™•ç†å·²è¨“ç·´æ¨¡çµ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40fcfd1b-0bbf-41f6-bcb5-73951ca3485c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"model_epoch_06.h5\", compile=False)\n",
    "model_config = loaded_model.get_config()\n",
    "#loaded_model.summary()\n",
    "\n",
    "# # Function to encode the image\n",
    "# def encode_image(image_path):\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def encode_image(image_object):\n",
    "    # Create a BytesIO object to hold the image data\n",
    "    image_bytes = io.BytesIO()\n",
    "\n",
    "    # Save the PIL image to the BytesIO object\n",
    "    image_object.save(image_bytes, format='JPEG')  # Adjust the format as needed\n",
    "\n",
    "    # Encode the image data in base64\n",
    "    encoded_image = base64.b64encode(image_bytes.getvalue()).decode('utf-8')\n",
    "\n",
    "    return encoded_image\n",
    "\n",
    "def pred(img):\n",
    "\n",
    "    # Resize the image to match the input shape of your model\n",
    "    img = img.resize((256, 256))  # Adjust the size as needed\n",
    "    # Convert the image to a NumPy array\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    # Preprocess the image to match the model's input requirements\n",
    "    img_np = keras_image.img_to_array(img_np)\n",
    "    \n",
    "    img_for_plot = img_np / 255.0  # Normalize the image if necessary\n",
    "    \n",
    "    img_np = np.expand_dims(img_np, axis=0)  # Add a batch dimension\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(img_np)\n",
    "    \n",
    "    return img_for_plot, predictions\n",
    "\n",
    "def image_mod(img):\n",
    "    \n",
    "    image, predictions = pred(img)\n",
    "\n",
    "    print(predictions)\n",
    "    \n",
    "    result = \"\"\n",
    "    \n",
    "    if predictions[0][0] < 0.5:\n",
    "\n",
    "        result = \"fake image\"\n",
    "    else :\n",
    "        \n",
    "        result = \"true image\"\n",
    "\n",
    "    return result\n",
    "\n",
    "def chatbtn(content):\n",
    "    \n",
    "    print(content)\n",
    "    \n",
    "    return content\n",
    "\n",
    "def display_image_from_video(video):\n",
    "\n",
    "    capture_image = cv.VideoCapture(video) \n",
    "    # ç²å–è¦–é »ä¸­çš„ä¸€å¹€ï¼Œè®Šæ•¸åˆ†åˆ¥ç‚ºæ˜¯å¦æˆåŠŸè®€å–äº†ä¸€å¹€ä»¥åŠæ•ç²çš„åœ–åƒå¹€\n",
    "    ret, frame = capture_image.read()\n",
    "\n",
    "    img = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    img = cv.resize(img, (256, 256))  # èª¿æ•´å¤§å°\n",
    "    img_for_plot = img / 255.0  # æ­£è¦åŒ–åœ–åƒ\n",
    "    \n",
    "    img_np = np.expand_dims(img, axis=0)  # Add a batch dimension\n",
    "    \n",
    "#     # Make predictions\n",
    "#     predictions = loaded_model.predict(img_np)\n",
    "    \n",
    "#     result = \"\"\n",
    "    \n",
    "#     if predictions[0][0] < 0.5:\n",
    "\n",
    "#         result = \"fake image\"\n",
    "#     else :\n",
    "        \n",
    "#         result = \"true image\"\n",
    "\n",
    "#     return result\n",
    "    return img_for_plot\n",
    "\n",
    "def take_pic():  \n",
    "    cam_port = 0\n",
    "    cam = cv2.VideoCapture(cam_port) \n",
    "    # reading the input using the camera \n",
    "    result, image = cam.read() \n",
    "    # If image will detected without any error,  \n",
    "    # show result \n",
    "    if result: \n",
    "        # showing result, it take frame name and image  \n",
    "        # output \n",
    "        cv2.imshow(\"images/GeeksForGeeks\", image) \n",
    "        # saving image in local storage \n",
    "        cv2.imwrite(\"images/GeeksForGeeks.png\", image) \n",
    "        # If keyboard interrupt occurs, destroy image  \n",
    "        # window \n",
    "        # cv2.waitKey(0) \n",
    "        # cv2.destroyWindow(\"GeeksForGeeks\") \n",
    "    else: \n",
    "        print(\"No image detected. Please! try again\") \n",
    "        \n",
    "# def Reply(message, chat_history):\n",
    "#     bot_message = random.choice([\"How are you?\", \"hello\", \"I'm very hungry\"])\n",
    "#     chat_history.append((message, bot_message))\n",
    "#     # time.sleep(2)\n",
    "#     return \"\", chat_history\n",
    "\n",
    "def Reply(imagebox, message, chat_history):\n",
    "    \n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(imagebox)\n",
    "    \n",
    "    start_idx = 0\n",
    "    result = ''\n",
    "    while start_idx < len(itemlist):\n",
    "        end_idx = min(start_idx + 1600, len(itemlist))\n",
    "        sub_list = itemlist[start_idx:end_idx]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": message},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        )  \n",
    "        for choice in response.choices:\n",
    "            result += choice.message.content\n",
    "        start_idx = end_idx\n",
    "\n",
    "    with open('output.txt', 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(result)\n",
    "\n",
    "    output = open(\"output.txt\", \"r\", encoding=\"utf-8\")\n",
    "    read_output = output.read()\n",
    "    \n",
    "    chat_history.append((message, read_output))\n",
    "    print(chat_history)\n",
    "    \n",
    "    time.sleep(10)\n",
    "    \n",
    "    return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d534885-2796-4907-9e69-9ec81d275c09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# title = \"\"\"<h1 align=\"center\">AIè‡‰éƒ¨è¾¨è­˜ğŸš€</h1>\"\"\"\n",
    "\n",
    "# with gr.Blocks(css = \"\"\".gradio-container {background-color: #3f7791}\"\"\") as demo:\n",
    "#     gr.HTML(title)\n",
    "#     gr.HTML('''<center><a href=\"https://github.com/kennywang112?tab=repositories\" alt=\"GitHub Repo\"></a></center>''')\n",
    "#     with gr.Row():\n",
    "#         with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "#             chatbot = gr.Chatbot(elem_id='chatbot')\n",
    "#             inputs = gr.Textbox(placeholder= \"Hi there!\")\n",
    "#             state = gr.State([])\n",
    "#             btn = gr.Button('ask')\n",
    "            \n",
    "#         btn.click(chatbtn, [inputs], [])\n",
    "\n",
    "#         with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "#             gr.Interface(\n",
    "#                 image_mod,\n",
    "#                 gr.Image(type=\"pil\"),\n",
    "#                 gr.components.Text(),\n",
    "#                 examples=[\n",
    "#                     os.path.join(\"images/real_face0.jpeg\"),\n",
    "#                     os.path.join(\"images/real_face1.jpeg\"),\n",
    "#                     os.path.join(\"images/fake_face1.jpeg\"),\n",
    "#                     os.path.join(\"images/GeeksForGeeks.png\"),\n",
    "#                 ],\n",
    "#             )\n",
    "            \n",
    "#             pic = gr.Button('take a pic')\n",
    "\n",
    "#             pic.click(take_pic)\n",
    "                \n",
    "#         with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "#             inputs = gr.components.Video()\n",
    "#             outputs = gr.components.Text()\n",
    "#             # outputs = gr.components.Image()\n",
    "#             update = gr.Button('åˆ¤æ–·å½±ç‰‡åœ–åƒ')\n",
    "\n",
    "#             update.click(display_image_from_video, inputs = [inputs], outputs = [outputs])\n",
    "    \n",
    "# demo.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8683c7-6f08-4e26-a9dc-d404e5d2a7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('è©³ç´°ä»‹ç´¹é€™å¼µåœ–', 'é€™å¼µåœ–ç‰‡æ˜¯ä¸€å¹…æç¹ª')]\n"
     ]
    }
   ],
   "source": [
    "title = \"\"\"<h1 align=\"center\">AIè‡‰éƒ¨è¾¨è­˜</h1>\"\"\"\n",
    "textbox = gr.Textbox(show_label=False, placeholder=\"Enter text and press ENTER\", container=False)\n",
    "\n",
    "with gr.Blocks(css = \"\"\".gradio-container {background-color: #3f7791}\"\"\") as demo:\n",
    "    \n",
    "    gr.HTML(title)\n",
    "    gr.HTML('''<center><a href=\"https://github.com/kennywang112?tab=repositories\" alt=\"GitHub Repo\"></a></center>''')\n",
    "    \n",
    "    state = gr.State()\n",
    "    \n",
    "    with gr.Row():\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "\n",
    "            # for image\n",
    "            imagebox = gr.Image(type=\"pil\")\n",
    "            outputs = gr.components.Text()\n",
    "            img_clk = gr.Button('åˆ¤æ–·åœ–åƒ')\n",
    "            img_clk.click(image_mod, inputs = [imagebox], outputs = [outputs])\n",
    "            image_process_mode = gr.Radio(\n",
    "                [\"Crop\", \"Resize\", \"Pad\", \"Default\"],\n",
    "                value=\"Default\",\n",
    "                label=\"Preprocess for non-square image\", visible=False)\n",
    "            cur_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "            ex = gr.Examples(examples=[\n",
    "                [f\"{cur_dir}/images/fake_face0.jpeg\", \"ä½ è¦ºå¾—é€™å¼µåœ–ç‰‡æ˜¯çœŸçš„é‚„æ˜¯å‡çš„\"],\n",
    "                [f\"{cur_dir}/images/fake_face1.jpeg\", \"è©³ç´°ä»‹ç´¹é€™å¼µåœ–\"],\n",
    "                [f\"{cur_dir}/images/GeeksForGeeks.png\", \"å½¢å®¹é€™å¼µåœ–ç‰‡\"],\n",
    "            ], inputs = [imagebox, textbox])\n",
    "            \n",
    "        with gr.Column(scale=2):\n",
    "            \n",
    "            # video\n",
    "            inputs = gr.components.Video()\n",
    "            outputs = gr.components.Text()\n",
    "            update = gr.Button('åˆ¤æ–·å½±ç‰‡åœ–åƒ')\n",
    "            update.click(display_image_from_video, inputs = [inputs], outputs = [outputs])\n",
    "            \n",
    "            pic = gr.Button('æ‹ç…§')\n",
    "            pic.click(take_pic)\n",
    "            \n",
    "        with gr.Column(scale=6):\n",
    "            \n",
    "            chatbot = gr.Chatbot(elem_id=\"chatbot\", label=\"Chatbot\", height=550)\n",
    "            \n",
    "            with gr.Row():\n",
    "                    \n",
    "                with gr.Column(scale=1, min_width=50):\n",
    "                    msg = textbox.render()\n",
    "\n",
    "        # chatbox\n",
    "        msg.submit(Reply, [imagebox, msg, chatbot], [msg, chatbot])\n",
    "        \n",
    "demo.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b105a66-4940-4896-8433-899279abaaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
