{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6860154d-5760-4c6e-a55a-f65e41c147cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import gradio as gr\n",
    "import os\n",
    "import openai\n",
    "import cv2\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661cb30f-e2e1-4874-84f6-7d20c4fedb54",
   "metadata": {},
   "source": [
    "## æ¸¬è©¦gpt api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277e89ba-da6b-4e35-a588-07842518f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/texes.txt', 'r', encoding='utf-8') as fh:\n",
    "    tmp = fh.read()\n",
    "    itemlist = tmp.split(',')\n",
    "\n",
    "itemlist = str(itemlist)\n",
    "itemlist\n",
    "\n",
    "keyfile = open(\"key.txt\", \"r\")\n",
    "key = keyfile.readline()\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae79f28-3a0a-46be-b33d-6a21191b6610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¥½çš„ï¼Œä¸ºæ‚¨è®²ä¸€ä¸ªç¬‘è¯ï¼š\n",
      "\n",
      "æœ‰ä¸€å¤©ï¼Œå°æ˜å»æ‰¾ä»–çš„æœ‹å‹å°åç©ã€‚å°æ˜æ•²å¼€äº†å°åå®¶çš„å¤§é—¨ï¼Œä¸€ä¸ªé™Œç”Ÿäººå‡ºç°åœ¨é—¨å£ã€‚å°æ˜ç–‘æƒ‘åœ°é—®ï¼šâ€œä½ æ˜¯å°åçš„çˆ¸çˆ¸å—ï¼Ÿâ€é™Œç”Ÿäººç¬‘ç€å›ç­”ï¼šâ€œä¸æ˜¯ï¼Œæˆ‘æ˜¯ä»–çš„å¤§å§¨å¦ˆã€‚â€å°æ˜å¬äº†è¿™ä¸ªç­”æ¡ˆï¼Œçªå¤§çœ¼ç›è¯´ï¼šâ€œå“‡ï¼Œä½ æ˜¯å¤ªå¼ºäº†ï¼å±…ç„¶å¯ä»¥ç»™ç”·ç”Ÿæ¥å¤§å§¨å¦ˆï¼â€\n"
     ]
    }
   ],
   "source": [
    "start_idx = 0\n",
    "result = ''\n",
    "while start_idx < len(itemlist):\n",
    "    end_idx = min(start_idx + 1600, len(itemlist))\n",
    "    sub_list = itemlist[start_idx:end_idx]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
    "            {\"role\": \"user\", \"content\": sub_list}\n",
    "        ]\n",
    "    )  \n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    start_idx = end_idx\n",
    "\n",
    "with open('output.txt', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(result)\n",
    "\n",
    "output = open(\"output.txt\", \"r\", encoding=\"utf-8\")\n",
    "print(output.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bcf9d-dcd7-430f-ae33-86e2682a7b91",
   "metadata": {},
   "source": [
    "## è™•ç†å·²è¨“ç·´æ¨¡çµ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "40fcfd1b-0bbf-41f6-bcb5-73951ca3485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"model_epoch_06.h5\", compile=False)\n",
    "model_config = loaded_model.get_config()\n",
    "#loaded_model.summary()\n",
    "\n",
    "def pred(img):\n",
    "\n",
    "    # Resize the image to match the input shape of your model\n",
    "    img = img.resize((256, 256))  # Adjust the size as needed\n",
    "    # Convert the image to a NumPy array\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    # Preprocess the image to match the model's input requirements\n",
    "    img_np = keras_image.img_to_array(img_np)\n",
    "    \n",
    "    img_for_plot = img_np / 255.0  # Normalize the image if necessary\n",
    "    \n",
    "    img_np = np.expand_dims(img_np, axis=0)  # Add a batch dimension\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(img_np)\n",
    "    \n",
    "    return img_for_plot, predictions\n",
    "\n",
    "def image_mod(img):\n",
    "    \n",
    "    image, predictions = pred(img)\n",
    "\n",
    "    print(predictions)\n",
    "    \n",
    "    result = \"\"\n",
    "    \n",
    "    if predictions[0][0] < 0.5:\n",
    "\n",
    "        result = \"fake image\"\n",
    "    else :\n",
    "        \n",
    "        result = \"true image\"\n",
    "\n",
    "    return result\n",
    "\n",
    "def chatbtn(content):\n",
    "    \n",
    "    print(content)\n",
    "    \n",
    "    return content\n",
    "\n",
    "def display_image_from_video(video):\n",
    "\n",
    "    capture_image = cv.VideoCapture(video) \n",
    "    # ç²å–è¦–é »ä¸­çš„ä¸€å¹€ï¼Œè®Šæ•¸åˆ†åˆ¥ç‚ºæ˜¯å¦æˆåŠŸè®€å–äº†ä¸€å¹€ä»¥åŠæ•ç²çš„åœ–åƒå¹€\n",
    "    ret, frame = capture_image.read()\n",
    "\n",
    "    img = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    img = cv.resize(img, (256, 256))  # èª¿æ•´å¤§å°\n",
    "    img_for_plot = img / 255.0  # æ­£è¦åŒ–åœ–åƒ\n",
    "    \n",
    "    img_np = np.expand_dims(img, axis=0)  # Add a batch dimension\n",
    "    \n",
    "#     # Make predictions\n",
    "#     predictions = loaded_model.predict(img_np)\n",
    "    \n",
    "#     result = \"\"\n",
    "    \n",
    "#     if predictions[0][0] < 0.5:\n",
    "\n",
    "#         result = \"fake image\"\n",
    "#     else :\n",
    "        \n",
    "#         result = \"true image\"\n",
    "\n",
    "#     return result\n",
    "    return img_for_plot\n",
    "\n",
    "def take_pic():  \n",
    "    cam_port = 0\n",
    "    cam = cv2.VideoCapture(cam_port) \n",
    "    # reading the input using the camera \n",
    "    result, image = cam.read() \n",
    "    # If image will detected without any error,  \n",
    "    # show result \n",
    "    if result: \n",
    "        # showing result, it take frame name and image  \n",
    "        # output \n",
    "        cv2.imshow(\"images/GeeksForGeeks\", image) \n",
    "        # saving image in local storage \n",
    "        cv2.imwrite(\"images/GeeksForGeeks.png\", image) \n",
    "        # If keyboard interrupt occurs, destroy image  \n",
    "        # window \n",
    "        # cv2.waitKey(0) \n",
    "        # cv2.destroyWindow(\"GeeksForGeeks\") \n",
    "    else: \n",
    "        print(\"No image detected. Please! try again\") \n",
    "        \n",
    "# def Reply(message, chat_history):\n",
    "#     bot_message = random.choice([\"How are you?\", \"hello\", \"I'm very hungry\"])\n",
    "#     chat_history.append((message, bot_message))\n",
    "#     # time.sleep(2)\n",
    "#     return \"\", chat_history\n",
    "\n",
    "def Reply(message, chat_history):\n",
    "    \n",
    "    start_idx = 0\n",
    "    result = ''\n",
    "    while start_idx < len(itemlist):\n",
    "        end_idx = min(start_idx + 1600, len(itemlist))\n",
    "        sub_list = itemlist[start_idx:end_idx]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a chatbot\"},\n",
    "                {\"role\": \"user\", \"content\": message}\n",
    "            ]\n",
    "        )  \n",
    "        for choice in response.choices:\n",
    "            result += choice.message.content\n",
    "        start_idx = end_idx\n",
    "\n",
    "    with open('output.txt', 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(result)\n",
    "\n",
    "    output = open(\"output.txt\", \"r\", encoding=\"utf-8\")\n",
    "    # print(output.read())\n",
    "    \n",
    "    chat_history.append((message, output))\n",
    "    \n",
    "    return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d534885-2796-4907-9e69-9ec81d275c09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# title = \"\"\"<h1 align=\"center\">AIè‡‰éƒ¨è¾¨è­˜ğŸš€</h1>\"\"\"\n",
    "\n",
    "# with gr.Blocks(css = \"\"\".gradio-container {background-color: #3f7791}\"\"\") as demo:\n",
    "#     gr.HTML(title)\n",
    "#     gr.HTML('''<center><a href=\"https://github.com/kennywang112?tab=repositories\" alt=\"GitHub Repo\"></a></center>''')\n",
    "#     with gr.Row():\n",
    "#         with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "#             chatbot = gr.Chatbot(elem_id='chatbot')\n",
    "#             inputs = gr.Textbox(placeholder= \"Hi there!\")\n",
    "#             state = gr.State([])\n",
    "#             btn = gr.Button('ask')\n",
    "            \n",
    "#         btn.click(chatbtn, [inputs], [])\n",
    "\n",
    "#         with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "#             gr.Interface(\n",
    "#                 image_mod,\n",
    "#                 gr.Image(type=\"pil\"),\n",
    "#                 gr.components.Text(),\n",
    "#                 examples=[\n",
    "#                     os.path.join(\"images/real_face0.jpeg\"),\n",
    "#                     os.path.join(\"images/real_face1.jpeg\"),\n",
    "#                     os.path.join(\"images/fake_face1.jpeg\"),\n",
    "#                     os.path.join(\"images/GeeksForGeeks.png\"),\n",
    "#                 ],\n",
    "#             )\n",
    "            \n",
    "#             pic = gr.Button('take a pic')\n",
    "\n",
    "#             pic.click(take_pic)\n",
    "                \n",
    "#         with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "#             inputs = gr.components.Video()\n",
    "#             outputs = gr.components.Text()\n",
    "#             # outputs = gr.components.Image()\n",
    "#             update = gr.Button('åˆ¤æ–·å½±ç‰‡åœ–åƒ')\n",
    "\n",
    "#             update.click(display_image_from_video, inputs = [inputs], outputs = [outputs])\n",
    "    \n",
    "# demo.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8683c7-6f08-4e26-a9dc-d404e5d2a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\"<h1 align=\"center\">AIè‡‰éƒ¨è¾¨è­˜</h1>\"\"\"\n",
    "textbox = gr.Textbox(show_label=False, placeholder=\"Enter text and press ENTER\", container=False)\n",
    "\n",
    "with gr.Blocks(css = \"\"\".gradio-container {background-color: #3f7791}\"\"\") as demo:\n",
    "    \n",
    "    gr.HTML(title)\n",
    "    gr.HTML('''<center><a href=\"https://github.com/kennywang112?tab=repositories\" alt=\"GitHub Repo\"></a></center>''')\n",
    "    \n",
    "    state = gr.State()\n",
    "    \n",
    "    with gr.Row():\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "\n",
    "            # for image\n",
    "            imagebox = gr.Image(type=\"pil\")\n",
    "            outputs = gr.components.Text()\n",
    "            img_clk = gr.Button('åˆ¤æ–·åœ–åƒ')\n",
    "            img_clk.click(image_mod, inputs = [imagebox], outputs = [outputs])\n",
    "            image_process_mode = gr.Radio(\n",
    "                [\"Crop\", \"Resize\", \"Pad\", \"Default\"],\n",
    "                value=\"Default\",\n",
    "                label=\"Preprocess for non-square image\", visible=False)\n",
    "            cur_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "            gr.Examples(examples=[\n",
    "                [f\"{cur_dir}/images/fake_face0.jpeg\", \"ä½ è¦ºå¾—é€™å¼µåœ–ç‰‡æ˜¯çœŸçš„é‚„æ˜¯å‡çš„\"],\n",
    "                [f\"{cur_dir}/images/fake_face1.jpeg\", \"å½¢å®¹é€™å¼µåœ–ç‰‡\"],\n",
    "                [f\"{cur_dir}/images/GeeksForGeeks.png\", \"å½¢å®¹é€™å¼µåœ–ç‰‡\"],\n",
    "            ], inputs = [imagebox, textbox])\n",
    "            \n",
    "            \n",
    "        with gr.Column(scale=2):\n",
    "            \n",
    "            # video\n",
    "            inputs = gr.components.Video()\n",
    "            outputs = gr.components.Text()\n",
    "            update = gr.Button('åˆ¤æ–·å½±ç‰‡åœ–åƒ')\n",
    "            update.click(display_image_from_video, inputs = [inputs], outputs = [outputs])\n",
    "            \n",
    "            pic = gr.Button('æ‹ç…§')\n",
    "            pic.click(take_pic)\n",
    "            \n",
    "        with gr.Column(scale=6):\n",
    "            \n",
    "            chatbot = gr.Chatbot(elem_id=\"chatbot\", label=\"Chatbot\", height=550)\n",
    "            \n",
    "            with gr.Row():\n",
    "                    \n",
    "                with gr.Column(scale=1, min_width=50):\n",
    "                    \n",
    "                    msg = textbox.render()\n",
    "\n",
    "        # chatbox\n",
    "        msg.submit(Reply, [msg, chatbot], [msg, chatbot])\n",
    "        \n",
    "demo.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b105a66-4940-4896-8433-899279abaaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
